---
title: "Homework 3"
author: "Gianni Spiga"
date: "2023-01-30"
output:
  pdf_document: 
    toc: true
  
---

# Problem Set 2 

## Question 4

### a.) Repeat the Poisson regression fit for the Melanoma data and obtain Pearson and deviance residuals.

Below is the Poisson model for our melanoma data, as well as the first 5 residual values for both Pearson and Deviance residuals. 

```{r, echo = FALSE}
library(knitr)

mela <- read.table("melanoma.txt", header = TRUE)

glm.mela <-
  glm(totalincidence ~ years + sunspotnumber,
      data = mela,
      family = poisson())
sum.mela <- summary(glm.mela)
kable(sum.mela$coefficients)

residPear <- residuals(glm.mela, type = "pearson")
residDev <- residuals(glm.mela, type = "deviance")

residData <- data.frame(residPear, residDev)
names(residData) <- c("Pearson", "Deviance")
kable(head(residData, 5))
```

### b.) 

We first print the summary statistics for both residuals. We can see that they are quite similar in measures of summary statistics.

```{r, echo = F, out.width="50%"}
kable(summary(residData))

# Boxplots of both residual types
boxplot(residData)

# Residuals vs fitted values
plot(
  glm.mela$fitted.values,
  residData[, 1],
  main = "Pearson Residuals vs Fitted Values",
  xlab = "Fitted Values",
  ylab = "Pearson Residuals"
)

plot(
  glm.mela$fitted.values,
  residData[, 2],
  main = "Deviance Residual vs Fitted Values",
  xlab = "Fitted Values",
  ylab = "Deviance Residuals"
)
```

Based on the plots, we can see that the deviance and pearson residuals are very similar to each other, thus indicating that our model is a good fit. 

### c.) 
There is no indication of a lack of fit in the reisdual plots.

### d.)
```{r, echo = FALSE}
# Deviance table
kable(anova(glm.mela, test = "Chisq"))
```

### e.)

```{r, echo = FALSE}
library(MASS)
scope <- list(upper = ~years + sunspotnumber, lower = ~1)
mela.step <- stepAIC(glm.mela, trace = TRUE, scope = scope)
```

### f.)

Based off the stepwise regression, we would pick the model with the only predictor being years, since it has the lowest AIC. We can conclude that the best way to model the incidence of melanomas is to track the year it was acquired for each patient.

## Question 5

See written work

# Problem Set 3 

## Question 1, 3, 4

See written work

## Question 7

```{r, echo = FALSE}
chemo <- read.table("chemo.dat")
names(chemo) <-
  c(
    "ID",
    "1st.Period",
    "2nd.Period",
    "3rd.Period",
    "4th.Period",
    "Treatment",
    "Baseline",
    "Patient.Age"
  )
chemo["Seiz.Count"] <- chemo[, 2] + chemo[, 3] + chemo[, 4] + chemo[, 5]

chemo <- chemo[, -c(1:5)]
# Preview our cleaned dataset
kable(head(chemo))
```

Above we can see a small preview of the cleaned data set. Before we begin analysis, we will check if the data has any outliers. 

```{r, echo = F, out.width="65%"}
library(ggplot2)
library(plotly)

# Scatter of Treatment vs Seiz.Count
ggplot(data = chemo, aes(x = Seiz.Count, y = Treatment)) + geom_point()

# One point with a total amount of seizures over 300
kable(chemo[which(chemo["Seiz.Count"] >= 300),])

# Remove the outlier
chemo.out <- which(chemo["Seiz.Count"] >= 300)
chemo <- chemo[-49, ]
```

We can see that subject 49 has an abnormally high amount of seizures, so we will remove this observation from the data and begin analysis with our Poisson Regression model.

```{r, echo = F, out.width="65%"}
chemo.fit <-
  glm(
    Seiz.Count ~ as.factor(Treatment) + Baseline + Patient.Age,
    data = chemo,
    family = poisson()
  )
chemo.fit.sum <- summary(chemo.fit)
kable(chemo.fit.sum$coefficients)

# Check residuals
chemo.res.P <- residuals(chemo.fit, type = "pearson")
chemo.res.D <- residuals(chemo.fit, type = "deviance")

ggplot() + geom_boxplot(aes(x = "Pearson", y = chemo.res.P)) + geom_boxplot(aes(x = "Deviance", y = chemo.res.D)) + labs(y = "Values")

# Runs test
library(lawstat)
runs.test(y = chemo.res.P, plot.it = TRUE)
title(main = 'Pearson Residual Runs Test')
runs.test(y = chemo.res.D, plot.it = TRUE)
title(main = 'Deviance Residual Runs Test')
```

We can see that all of our predictors in the Poisson model are highly significan, meaning that with a null hypothesis of $\beta_i = 0$, we would reject. We can see from the coefficients that Baseline and Patient Age increase the log expected count of total seizures while the treatment type decreases the log expected count of seizures.

We will next check the goodness-of-fit comparing Deviance and Pearson residuals. From the boxplot above, we can see that our Pearson and Deviance Residuals are very similar, indicating that our model is a good fit. From the Runs Test, we can see that there is no indication of a non-random pattern, causing us to fail to reject the null hypothesis that the sequence of residuals was produced in a random manner. 

## Question 9

### a.)

```{r, echo = FALSE}
lung <- read.table("lung.dat", header = T)

lung.fit <-
  glm(
    cbind(Yes, No) ~ Dust + as.factor(Race) + as.factor(Sex) + as.factor(Smoker) + EmpLength,
    data = lung,
    family = "binomial"
  )

lung.step <- stepAIC(lung.fit, trace = F)
lung.step.fit <-
  glm(
    cbind(Yes, No) ~ Dust + as.factor(Smoker) + EmpLength,
    data = lung,
    family = "binomial"
  )
kable(lung.step$anova)

kable(anova(lung.fit, test = "Chi"))
```

When we perform a stepwise logistic regression with the AIC, we get a best model including Dustiness, Smoker Status, and Employment length. When we find the best model via a deviance table, we get a model that includes all the same variables as before as well as the Sex of the worker. Let's observe the residuals of the smaller model. 

```{r, echo = F, out.width="65%"}
lung.resid.P <- residuals(lung.step.fit, type = "pearson")
lung.resid.D <- residuals(lung.step.fit, type = "deviance")

ggplot() + geom_boxplot(aes(x = "Pearson", y = lung.resid.P)) + geom_boxplot(aes(x = "Deviance", y = lung.resid.D)) + labs(y = "Values")
```

We will pick the smaller model as our fit, since the deviance table is inconsistent since it depends on the order of variables, as well as the p-value for the additional variable is the highest. 

### b.) 

```{r, echo =FALSE}
#summary(lung.step.fit)
```

We would be curious in if if being a non-smoker status decreases chance of illness, so we would be interested in finding out if this rate was strictly greater than 0. We would test:

$$
H_0: \beta_{smoker} \geq 0\\
H_a: \beta_{smoker} < 0
$$
We can calculate this p-value by dividing the two tailed p-value by two, giving us a p-value of $0.000164$, leading us to reject $H_0$. 

### c.) 

```{r, echo = F, out.width="50%"}
# Find leverage points
lung.lev <- hatvalues(lung.step.fit)
lung.cook <- cooks.distance(lung.step.fit)
plot(lung.step.fit, which = c(4, 5))
```

From our first plot, we can see that that observation 49 has the highest Cooks distance, indicating that it is an influential outlier. We can also see more clearly from our second plot that observation is another high leverage outlier. 

### d.) 

```{r, echo = F}
lung.int <-
  glm(
    cbind(Yes, No) ~ (Dust * as.factor(Smoker) * EmpLength) * (Dust * as.factor(Smoker) * EmpLength),
    data = lung,
    family = "binomial"
  )
kable(summary(lung.int)$coefficients)
```

$$
H_0: A\beta = 0; A \in R^{5x6}, \beta \in R^6 \\ 
H_a: A\beta = 0; A \in R^{5x6}, \beta \in R^6 \\ 
$$

The degrees of freedom in this example would be 5. Based on the summary table, we should not have any interactions in this model, as none of them are significant. With this model, our smoker variable (main effect, not interaction), is also not significant.

# Provided Question 3

See written work.

# Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

# Written Work 